<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" data-content_root="../../../" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" metia="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="https://fg-research.com/_static/thumbnail.png" name="thumbnail"/>
<meta content="Forecasting Stock Returns with Liquid Neural Networks" name="description"/>
<meta content="Amazon SageMaker, Time Series, Liquid Neural Networks, Forecasting" name="keywords"/>
<title>Forecasting stock returns with liquid neural networks using the CfC SageMaker Algorithm | fg-research</title>
<meta content="Forecasting stock returns with liquid neural networks using the CfC SageMaker Algorithm | fg-research" property="og:title"/>
<meta content="Forecasting stock returns with liquid neural networks using the CfC SageMaker Algorithm | fg-research" name="twitter:title"/>
<link href="../../../_static/pygments.css?v=8d216cef" rel="stylesheet" type="text/css"/>
<link href="../../../_static/theme.css?v=5b4133db" rel="stylesheet" type="text/css"/>
<link href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" rel="stylesheet" type="text/css"/>
<link href="../../../_static/custom.css?v=65d6101a" rel="stylesheet" type="text/css"/>
<link href="../../../_static/awesome-sphinx-design.css?v=a54cf077" rel="stylesheet" type="text/css"/>
<link href="https://fg-research.com/blog/product/posts/cfc-tsf-equity-forecasting.html" rel="canonical"/>
<link href="../../../_static/favicon.ico" rel="icon"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="lstm-ad-ecg-anomaly-detection.html" rel="next" title="ECG anomaly detection with the LSTM-AD SageMaker Algorithm"/>
<link href="../index.html" rel="prev" title="Product"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../../../index.html"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">fg-research</span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../../../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">âŒ˜</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<a href="https://github.com/fg-research" rel="noopener nofollow" title="Visit GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md disabled:opacity-50 disabled:pointer-events-none hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg fill="currentColor" height="26px" style="margin-top:-2px;display:inline" viewbox="0 0 45 44" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.477.927C10.485.927.76 10.65.76 22.647c0 9.596 6.223 17.736 14.853 20.608 1.087.2 1.483-.47 1.483-1.047 0-.516-.019-1.881-.03-3.693-6.04 1.312-7.315-2.912-7.315-2.912-.988-2.51-2.412-3.178-2.412-3.178-1.972-1.346.149-1.32.149-1.32 2.18.154 3.327 2.24 3.327 2.24 1.937 3.318 5.084 2.36 6.321 1.803.197-1.403.759-2.36 1.379-2.903-4.823-.548-9.894-2.412-9.894-10.734 0-2.37.847-4.31 2.236-5.828-.224-.55-.969-2.759.214-5.748 0 0 1.822-.584 5.972 2.226 1.732-.482 3.59-.722 5.437-.732 1.845.01 3.703.25 5.437.732 4.147-2.81 5.967-2.226 5.967-2.226 1.185 2.99.44 5.198.217 5.748 1.392 1.517 2.232 3.457 2.232 5.828 0 8.344-5.078 10.18-9.916 10.717.779.67 1.474 1.996 1.474 4.021 0 2.904-.027 5.247-.027 5.96 0 .58.392 1.256 1.493 1.044C37.981 40.375 44.2 32.24 44.2 22.647c0-11.996-9.726-21.72-21.722-21.72" fill="currentColor" fill-rule="evenodd"></path></svg>
</div>
</a>
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../../../index.html"><span class="font-bold text-clip whitespace-nowrap">fg-research</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms/time-series-forecasting/index.html">Time Series Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms/time-series-anomaly-detection/index.html">Time Series Anomaly Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms/time-series-clustering/index.html">Time Series Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms/time-series-classification/index.html">Time Series Classification</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Blog</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Product</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../general/index.html">General</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Terms and Conditions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../terms/disclaimer/index.html">Disclaimer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../terms/eula/index.html">EULA</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../../../index.html">
<span class="hidden md:inline">fg-research</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><a class="hover:text-foreground overflow-hidden text-ellipsis whitespace-nowrap" href="../index.html">Product</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">Forecasting stock returns with liquid neural networks using the CfC SageMaker Algorithm</span>
</nav>
<div id="content" role="main">
<section id="forecasting-stock-returns-with-liquid-neural-networks-using-the-cfc-sagemaker-algorithm">
<h1>Forecasting stock returns with liquid neural networks using the CfC SageMaker Algorithm<a class="headerlink" href="#forecasting-stock-returns-with-liquid-neural-networks-using-the-cfc-sagemaker-algorithm" title="Link to this heading">Â¶</a></h1>
<p>
Stock return forecasting has been extensively studied by both academic researchers and
industry practitioners. Numerous machine learning models have been proposed for this purpose,
ranging from simple linear regressions to complex deep learning models <a href="#references">[1]</a>.
In this post, we examine the performance of liquid neural networks <a href="#references">[4]</a>
<a href="#references">[5]</a>, a new neural network architecture for sequential data.
</p>
<p>
We will use our Amazon SageMaker implementation of liquid neural networks for probabilistic time series
forecasting, the <a href="file:///Users/flaviagiammarino/website/docs/algorithms/time-series-forecasting/index.html#cfc-sagemaker-algorithm" target="_blank"> CfC SageMaker algorithm</a>.
We will forecast the conditional mean and the conditional standard deviation of the 30-day returns of
the S&amp;P 500 using as input the S&amp;P 500 realized volatility as well as several implied volatility indices,
similar to <a href="#references">[2]</a>.
</p>
<p>
We will use the daily close prices from the 30<sup>th</sup> of June 2022 to
the 29<sup>th</sup> of June 2024, which we will download with the <a href="https://github.com/ranaroussi/yfinance" target="_blank">Yahoo! Finance Python API</a>.
We will train the model on the data up to the 8<sup>th</sup> of September 2023,
and use the trained model to predict the subsequent data up to the 29<sup>th</sup> of June 2024.
We will find that the CfC SageMaker algorithm achieves a mean absolute error of 1.4% and
a mean directional accuracy of 97.5%.
</p><section id="model">
<h2>Model<a class="headerlink" href="#model" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#model'">Â¶</a></h2>
<p>
The closed-form continuous-depth network (CfC) is a new neural network architecture for
sequential data <a href="#references">[4]</a>. CfCs belong to the class of continuous-time
recurrent neural networks (CT-RNNs) <a href="#references">[3]</a>, where the evolution of
the hidden state over time is described by an Ordinary Differential Equation (ODE).
</p>
<p>
CfCs use the Liquid Time Constant (LTC) ODE <a href="#references">[5]</a>, where both the
derivative and the time constant of the hidden state are determined by a neural network.
Differently from other CT-RNNs (including LTCs), which use a numerical solver to find the
ODE solution, CfCs use an approximate closed-form solution. As a results, CfCs achieve
faster training and inference performance than other CT-RNNs.
</p><p>The hidden state <span class="math notranslate nohighlight">\(x\)</span> of a CfC at time <span class="math notranslate nohighlight">\(t\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[x(t) = \sigma(-f(x, I; \theta_f)t) \odot g(x, I; \theta_g) + [1 - \sigma(-[f(x, I; \theta_f)]t)] \odot h(x, I; \theta_h)\]</div>
<p>where <span class="math notranslate nohighlight">\(\odot\)</span> is the Hadamard product, <span class="math notranslate nohighlight">\(\sigma\)</span> is the sigmoid function, <span class="math notranslate nohighlight">\(I\)</span>
is the input sequence, while <span class="math notranslate nohighlight">\(f\)</span>, <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(h\)</span> are neural networks. The three
neural networks <span class="math notranslate nohighlight">\(f\)</span>, <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(h\)</span> share a common backbone, which is a stack of
fully-connected layers with non-linear activation.</p>
<p>The backbone is followed by three separate neural network heads. The head of the <span class="math notranslate nohighlight">\(g\)</span> and
<span class="math notranslate nohighlight">\(h\)</span> neural networks is a fully-connected layer with hyperbolic tangent activation. The head
of the <span class="math notranslate nohighlight">\(f\)</span> neural network is an affine function <span class="math notranslate nohighlight">\(b + a(\Delta t)\)</span> where <span class="math notranslate nohighlight">\(\Delta t\)</span>
is the time span (or time increment) between consecutive time steps, while the intercept <span class="math notranslate nohighlight">\(b\)</span>
and slope <span class="math notranslate nohighlight">\(a\)</span> are the outputs of two fully-connected layers with linear activation.</p>
</section>
<section id="data">
<h2>Data<a class="headerlink" href="#data" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#data'">Â¶</a></h2>
<section id="outputs">
<h3>Outputs<a class="headerlink" href="#outputs" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#outputs'">Â¶</a></h3>
<p>The model outputs are the 30-day returns of the S&amp;P 500, which are calculated as follows</p>
<div class="math notranslate nohighlight">
\[y(t) = \ln{P(t)} - \ln{P(t-30)}\]</div>
<p>for each day <span class="math notranslate nohighlight">\(t\)</span>, where <span class="math notranslate nohighlight">\(P(t)\)</span> is the close price of the S&amp;P 500 on day <span class="math notranslate nohighlight">\(t\)</span>.</p>
</section>
<section id="inputs">
<h3>Inputs<a class="headerlink" href="#inputs" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#inputs'">Â¶</a></h3>
<p>The model uses as input the previous 30-day returns of the S&amp;P 500 as well as the past values
of the following volatility indicators:</p>
<ul class="simple">
<li><p><em>RVOL</em>: The realized volatility of the S&amp;P 500, calculated as the 30-day rolling sample standard deviation of the S&amp;P 500 daily log returns.</p></li>
<li><p><em>VIX</em>: The <a class="reference external" href="https://www.cboe.com/us/indices/dashboard/vix/">VIX index</a> measures the 30-day implied volatility of S&amp;P 500 options.</p></li>
<li><p><em>VVIX</em>: The <a class="reference external" href="https://www.cboe.com/us/indices/dashboard/vvix/">VVIX index</a> reflects the 30-day expected volatility of the VIX.</p></li>
<li><p><em>VXN</em>: The <a class="reference external" href="https://www.cboe.com/us/indices/dashboard/vxn/">VXN index</a> measures the 30-day implied volatility of NASDAQ 100 options.</p></li>
<li><p><em>GVZ</em>: The <a class="reference external" href="https://www.cboe.com/us/indices/dashboard/gvz/">GVZ index</a> measures the 30-day implied volatility of GLD options.</p></li>
<li><p><em>OVX</em>: The <a class="reference external" href="https://www.cboe.com/us/indices/dashboard/ovx/">OVX index</a> measures the 30-day implied volatility of USO options.</p></li>
</ul>
<p><em>RVOL</em> is a backward-looking indicator, as it measures the volatility over the past 30 days,
while <em>VIX</em>, <em>VVIX</em>, <em>VXN</em>, <em>GVZ</em>, and <em>OVX</em> are forward-looking indicators, as they reflect the marketâ€™s
expectation of what the volatility will be over the next 30 days.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that we use the same inputs as in <a class="reference external" href="file:///Users/flaviagiammarino/website/docs/blog/product/posts/cfc-tsf-equity-forecasting.html#references">[2]</a>,
with the exception of the <em>PUTCALL</em> index, which we had to exclude as its historical time series is not publicly available.</p>
</div>
</section>
</section>
<section id="code">
<h2>Code<a class="headerlink" href="#code" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#code'">Â¶</a></h2>
<section id="environment-set-up">
<h3>Environment Set-Up<a class="headerlink" href="#environment-set-up" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#environment-set-up'">Â¶</a></h3>
<p>We start by importing all the dependencies and setting up the SageMaker environment.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>To be able to run the code below, you need to have an active subscription to the
CfC SageMaker algorithm. You can subscribe to a free trial from the
<a class="reference external" href="https://aws.amazon.com/marketplace/pp/prodview-7s4giphluwgta">AWS Marketplace</a>
in order to get your Amazon Resource Name (ARN).
In this post we use version 1.6 of the CfC SageMaker algorithm, which runs in the
PyTorch 2.1.0 Python 3.10 deep learning container.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="kn">import</span> <span class="nn">io</span>
</span><span id="line-2"><span class="kn">import</span> <span class="nn">sagemaker</span>
</span><span id="line-3"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span><span id="line-4"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="line-5"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span><span id="line-6"><span class="kn">import</span> <span class="nn">yfinance</span> <span class="k">as</span> <span class="nn">yf</span>
</span><span id="line-7"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">root_mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span>
</span><span id="line-8">
</span><span id="line-9"><span class="c1"># SageMaker session</span>
</span><span id="line-10"><span class="n">sagemaker_session</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
</span><span id="line-11">
</span><span id="line-12"><span class="c1"># SageMaker role</span>
</span><span id="line-13"><span class="n">role</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">get_execution_role</span><span class="p">()</span>
</span><span id="line-14">
</span><span id="line-15"><span class="c1"># S3 bucket</span>
</span><span id="line-16"><span class="n">bucket</span> <span class="o">=</span> <span class="n">sagemaker_session</span><span class="o">.</span><span class="n">default_bucket</span><span class="p">()</span>
</span><span id="line-17">
</span><span id="line-18"><span class="c1"># EC2 instance</span>
</span><span id="line-19"><span class="n">instance_type</span> <span class="o">=</span> <span class="s2">"ml.m5.4xlarge"</span>
</span></code></pre></div>
</div>
<p>After that we define the neural networkâ€™s context length and prediction length.
The context length is the number of past time steps used as input,
while the prediction length is the number of future time steps to be predicted.
We set both of them equal to 30 days, that is we use the previous 30 values
of the inputs to predict the next 30 values of the output.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># number of time steps used as input</span>
</span><span id="line-2"><span class="n">context_length</span> <span class="o">=</span> <span class="mi">30</span>
</span><span id="line-3">
</span><span id="line-4"><span class="c1"># number of time steps to output</span>
</span><span id="line-5"><span class="n">prediction_length</span> <span class="o">=</span> <span class="mi">30</span>
</span></code></pre></div>
</div>
</section>
<section id="data-preparation">
<h3>Data Preparation<a class="headerlink" href="#data-preparation" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#data-preparation'">Â¶</a></h3>
Next, we download the daily close price time series from the 30<sup>th</sup> of June 2022 to
the 29<sup>th</sup> of June 2024 with the
<a href="https://github.com/ranaroussi/yfinance" target="_blank">Yahoo! Finance Python API</a>.<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># download the data</span>
</span><span id="line-2"><span class="n">tickers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"^SPX"</span><span class="p">,</span> <span class="s2">"^VIX"</span><span class="p">,</span> <span class="s2">"^VVIX"</span><span class="p">,</span> <span class="s2">"^VXN"</span><span class="p">,</span> <span class="s2">"^GVZ"</span><span class="p">,</span> <span class="s2">"^OVX"</span><span class="p">]</span>
</span><span id="line-3"><span class="n">dataset</span> <span class="o">=</span> <span class="n">yf</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tickers</span><span class="p">),</span> <span class="n">start</span><span class="o">=</span><span class="s2">"2022-06-30"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"2024-06-29"</span><span class="p">)</span>
</span><span id="line-4">
</span><span id="line-5"><span class="c1"># extract the close prices</span>
</span><span id="line-6"><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"Close"</span><span class="p">]</span>
</span><span id="line-7"><span class="n">dataset</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-8">
</span><span id="line-9"><span class="c1"># forward fill any missing values</span>
</span><span id="line-10"><span class="n">dataset</span><span class="o">.</span><span class="n">ffill</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
</div>
<p>We then calculate the S&amp;P 500 30-day returns and 30-day realized volatility.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># calculate the returns</span>
</span><span id="line-2"><span class="n">dataset</span><span class="p">[</span><span class="s2">"Return30"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"^SPX"</span><span class="p">])</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</span><span id="line-3">
</span><span id="line-4"><span class="c1"># calculate the realized volatility</span>
</span><span id="line-5"><span class="n">dataset</span><span class="p">[</span><span class="s2">"RVOL"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">"^SPX"</span><span class="p">])</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-6">
</span><span id="line-7"><span class="c1"># drop the prices</span>
</span><span id="line-8"><span class="n">dataset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">"^SPX"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-9">
</span><span id="line-10"><span class="c1"># drop the missing values</span>
</span><span id="line-11"><span class="n">dataset</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-12">
</span><span id="line-13"><span class="c1"># move the returns to the first column</span>
</span><span id="line-14"><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[[</span><span class="s2">"Return30"</span><span class="p">]</span> <span class="o">+</span> <span class="n">dataset</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">"Return30"</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>
</span></code></pre></div>
</div>
<p>The dataset contains 502 daily observations which, after dropping the missing values
resulting from the calculation of the returns of the realized volatility, are reduced to 472.</p>
<img alt="30-day returns, 30-day realized volatility and volatility indices from 2022-08-12 to 2024-06-29" class="blog-post-image" id="cfc-tsf-forecasting-time-series" src="https://fg-research-blog.s3.eu-west-1.amazonaws.com/equity-forecasting/time_series_light.png"/>
<p class="blog-post-image-caption">30-day returns, 30-day realized volatility and volatility indices from 2022-08-12 to 2024-06-29.</p><p>We now proceed to renaming the columns in the format required by the CfC SageMaker algorithm,
where the output names should start with <code class="code docutils literal notranslate"><span class="pre">"y"</span></code> while the input names should start with <code class="code docutils literal notranslate"><span class="pre">"x"</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="n">dataset</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"y"</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="sa">f</span><span class="s2">"x</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
</span></code></pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that the algorithm always uses the past values of the outputs as inputs,
and there is therefore no need to include the outputs among the inputs when preparing the data for the model.</p>
</div>
<p>After that we split the data into a training set and a test set. The training set includes the first 70% of
the data (270 observations), while the test set includes the last 30% of the data (202 observations).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># define the size of the test set</span>
</span><span id="line-2"><span class="n">test_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
</span><span id="line-3">
</span><span id="line-4"><span class="c1"># extract the training data</span>
</span><span id="line-5"><span class="n">training_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="o">-</span> <span class="n">test_size</span> <span class="o">-</span> <span class="n">context_length</span> <span class="o">-</span> <span class="n">prediction_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</span><span id="line-6">
</span><span id="line-7"><span class="c1"># extract the test data</span>
</span><span id="line-8"><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span> <span class="n">test_size</span> <span class="o">-</span> <span class="n">context_length</span> <span class="o">-</span> <span class="n">prediction_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:]</span>
</span></code></pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that the data is scaled internally by the algorithm, there is no need to scale the data beforehand.</p>
</div>
</section>
<section id="training">
<h3>Training<a class="headerlink" href="#training" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#training'">Â¶</a></h3>
<p>We now save the training data in S3, build the SageMaker estimator and run the training job.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># upload the training data to S3</span>
</span><span id="line-2"><span class="n">training_data</span> <span class="o">=</span> <span class="n">sagemaker_session</span><span class="o">.</span><span class="n">upload_string_as_file_body</span><span class="p">(</span>
</span><span id="line-3">    <span class="n">body</span><span class="o">=</span><span class="n">training_dataset</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="line-4">    <span class="n">bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span>
</span><span id="line-5">    <span class="n">key</span><span class="o">=</span><span class="s2">"training_dataset.csv"</span>
</span><span id="line-6"><span class="p">)</span>
</span><span id="line-7">
</span><span id="line-8"><span class="c1"># create the estimator</span>
</span><span id="line-9"><span class="n">estimator</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">AlgorithmEstimator</span><span class="p">(</span>
</span><span id="line-10">    <span class="n">algorithm_arn</span><span class="o">=</span><span class="n">algo_arn</span><span class="p">,</span>
</span><span id="line-11">    <span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span>
</span><span id="line-12">    <span class="n">instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="line-13">    <span class="n">instance_type</span><span class="o">=</span><span class="n">instance_type</span><span class="p">,</span>
</span><span id="line-14">    <span class="n">input_mode</span><span class="o">=</span><span class="s2">"File"</span><span class="p">,</span>
</span><span id="line-15">    <span class="n">sagemaker_session</span><span class="o">=</span><span class="n">sagemaker_session</span><span class="p">,</span>
</span><span id="line-16">    <span class="n">hyperparameters</span><span class="o">=</span><span class="p">{</span>
</span><span id="line-17">        <span class="s2">"context-length"</span><span class="p">:</span> <span class="n">context_length</span><span class="p">,</span>
</span><span id="line-18">        <span class="s2">"prediction-length"</span><span class="p">:</span> <span class="n">prediction_length</span><span class="p">,</span>
</span><span id="line-19">        <span class="s2">"sequence-stride"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="line-20">        <span class="s2">"hidden-size"</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
</span><span id="line-21">        <span class="s2">"backbone-layers"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="line-22">        <span class="s2">"backbone-units"</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>
</span><span id="line-23">        <span class="s2">"backbone-activation"</span><span class="p">:</span> <span class="s2">"lecun"</span><span class="p">,</span>
</span><span id="line-24">        <span class="s2">"backbone-dropout"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="line-25">        <span class="s2">"minimal"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="line-26">        <span class="s2">"no-gate"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="line-27">        <span class="s2">"use-mixed"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="line-28">        <span class="s2">"use-ltc"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="line-29">        <span class="s2">"batch-size"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
</span><span id="line-30">        <span class="s2">"lr"</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span>
</span><span id="line-31">        <span class="s2">"lr-decay"</span><span class="p">:</span> <span class="mf">0.9999</span><span class="p">,</span>
</span><span id="line-32">        <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
</span><span id="line-33">    <span class="p">}</span>
</span><span id="line-34"><span class="p">)</span>
</span><span id="line-35">
</span><span id="line-36"><span class="c1"># run the training job</span>
</span><span id="line-37"><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">({</span><span class="s2">"training"</span><span class="p">:</span> <span class="n">training_data</span><span class="p">})</span>
</span></code></pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that we are training a relatively small model with less than 5k parameters.</p>
</div>
</section>
<section id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#inference'">Â¶</a></h3>
<p>After the training job has been completed, we deploy the model to real-time endpoint that we can use for inference.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># define the endpoint inputs serializer</span>
</span><span id="line-2"><span class="n">serializer</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">serializers</span><span class="o">.</span><span class="n">CSVSerializer</span><span class="p">(</span><span class="n">content_type</span><span class="o">=</span><span class="s2">"text/csv"</span><span class="p">)</span>
</span><span id="line-3">
</span><span id="line-4"><span class="c1"># define the endpoint outputs deserializer</span>
</span><span id="line-5"><span class="n">deserializer</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">base_deserializers</span><span class="o">.</span><span class="n">PandasDeserializer</span><span class="p">(</span><span class="n">accept</span><span class="o">=</span><span class="s2">"text/csv"</span><span class="p">)</span>
</span><span id="line-6">
</span><span id="line-7"><span class="c1"># create the endpoint</span>
</span><span id="line-8"><span class="n">predictor</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">deploy</span><span class="p">(</span>
</span><span id="line-9">    <span class="n">initial_instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="line-10">    <span class="n">instance_type</span><span class="o">=</span><span class="n">instance_type</span><span class="p">,</span>
</span><span id="line-11"><span class="p">)</span>
</span></code></pre></div>
</div>
<p>Once the endpoint has been created, we can generate the test set predictions.
As we used rolling (or overlapping) returns, we are only interested in the last
element of each predicted sequence (recall that we set the prediction length to 30 days,
the same as the horizon of the returns).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="c1"># create a list for storing the predictions</span>
</span><span id="line-2"><span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-3">
</span><span id="line-4"><span class="c1"># loop across the dates</span>
</span><span id="line-5"><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">prediction_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="line-6">
</span><span id="line-7">    <span class="c1"># extract the data up to day t - 1</span>
</span><span id="line-8">    <span class="n">payload</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="n">context_length</span><span class="p">:</span> <span class="n">t</span><span class="p">]</span>
</span><span id="line-9">
</span><span id="line-10">    <span class="c1"># predict all rolling 30-day returns from day t to day t + 30</span>
</span><span id="line-11">    <span class="n">response</span> <span class="o">=</span> <span class="n">sagemaker_session</span><span class="o">.</span><span class="n">sagemaker_runtime_client</span><span class="o">.</span><span class="n">invoke_endpoint</span><span class="p">(</span>
</span><span id="line-12">        <span class="n">EndpointName</span><span class="o">=</span><span class="n">predictor</span><span class="o">.</span><span class="n">endpoint_name</span><span class="p">,</span>
</span><span id="line-13">        <span class="n">ContentType</span><span class="o">=</span><span class="s2">"text/csv"</span><span class="p">,</span>
</span><span id="line-14">        <span class="n">Body</span><span class="o">=</span><span class="n">payload</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="line-15">    <span class="p">)</span>
</span><span id="line-16">    <span class="n">response</span> <span class="o">=</span> <span class="n">deserializer</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s2">"Body"</span><span class="p">],</span> <span class="n">content_type</span><span class="o">=</span><span class="s2">"text/csv"</span><span class="p">)</span>
</span><span id="line-17">
</span><span id="line-18">    <span class="c1"># extract the predicted 30-day return from day t to day t + 30</span>
</span><span id="line-19">    <span class="n">prediction</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="line-20">
</span><span id="line-21">    <span class="c1"># extract the date corresponding to day t + 30</span>
</span><span id="line-22">    <span class="n">prediction</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="n">prediction_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>
</span><span id="line-23">
</span><span id="line-24">    <span class="c1"># save the prediction</span>
</span><span id="line-25">    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</span><span id="line-26">
</span><span id="line-27"><span class="c1"># cast the predictions to data frame</span>
</span><span id="line-28"><span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span id="line-29">
</span><span id="line-30"><span class="c1"># add the actual values</span>
</span><span id="line-31"><span class="n">predictions</span><span class="p">[</span><span class="s2">"y"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">[</span><span class="s2">"y"</span><span class="p">]</span>
</span></code></pre></div>
</div>
<img alt="Actual and predicted 30-day returns from 2023-12-04 to 2024-06-28" class="blog-post-image" id="cfc-tsf-forecasting-predictions" src="https://fg-research-blog.s3.eu-west-1.amazonaws.com/equity-forecasting/predictions_light.png"/>
<p class="blog-post-image-caption">Actual and predicted 30-day returns from 2023-12-04 to 2024-06-28.</p><p>We evaluate the test set predictions using the following metrics:</p>
<ul class="simple">
<li><p><em>RMSE</em>: The root mean squared error of the predicted values of the returns.</p></li>
<li><p><em>MAE</em>: The mean absolute error of the predicted values of the returns.</p></li>
<li><p><em>Accuracy</em>: The accuracy of the predicted signs of the returns.</p></li>
<li><p><em>F1</em>: The F1 score of the predicted signs of the returns.</p></li>
</ul>
<p>We find that the model achieves a mean absolute error of 1.4% and
a mean directional accuracy of 97.5%.</p>
We now generate the out-of-sample forecasts, that is we predict the 30-day returns
over 30 days beyond the end of the data (from the 29<sup>th</sup> of June 2024 to
the 28<sup>th</sup> of July 2024).<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In a real-life setting, we would retrain the model on all the available data
(i.e. until the 28&lt;sup&gt;th&lt;/sup&gt; of June 2024) before generating the out-of-sample
forecasts. To avoid running a new training job, we simply use the existing endpoint,
which uses the model trained on the data until the 8&lt;sup&gt;th&lt;/sup&gt; of September 2023.</p>
</div>
<img alt="30-day returns forecasts from 2024-06-29 to 2024-07-28" class="blog-post-image" id="cfc-tsf-forecasting-forecasts" src="https://fg-research-blog.s3.eu-west-1.amazonaws.com/equity-forecasting/forecasts_light.png"/>
<p class="blog-post-image-caption">30-day returns forecasts from 2024-06-29 to 2024-07-28.</p></section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#references'">Â¶</a></h2>
<p>[1] Kumbure, M.M., Lohrmann, C., Luukka, P. and Porras, J., (2022).
Machine learning techniques and data for stock market forecasting: A literature review.
<em>Expert Systems with Applications</em>, 197, p. 116659.
<a class="reference external" href="https://doi.org/10.1016/j.eswa.2022.116659">doi: 10.1016/j.eswa.2022.116659</a>.</p>
<p>[2] Campisi, G., Muzzioli, S. and De Baets, B., (2024).
A comparison of machine learning methods for predicting the direction of the US
stock market on the basis of volatility indices. <em>International Journal of Forecasting</em>, 40(3), pp. 869-880.
<a class="reference external" href="https://doi.org/10.1016/j.ijforecast.2023.07.002">doi: 10.1016/j.ijforecast.2023.07.002</a>.</p>
<p>[3] Funahashi, K.I. and Nakamura, Y., (1993). Approximation of dynamical systems by continuous
time recurrent neural networks. <em>Neural networks</em>, 6(6), pp.801-806.
<a class="reference external" href="https://doi.org/10.1016/S0893-6080(05)80125-X">doi: 10.1016/S0893-6080(05)80125-X</a>.</p>
<p>[4] Hasani, R., Lechner, M., Amini, A., Liebenwein, L., Ray, A., Tschaikowski, M., Teschl, G. and Rus, D., (2022).
Closed-form continuous-time neural networks. <em>Nature Machine Intelligence</em>, 4(11), pp. 992-1003.
<a class="reference external" href="https://doi.org/10.1038/s42256-022-00556-7">doi: 10.1038/s42256-022-00556-7</a>.</p>
<p>[5] Hasani, R., Lechner, M., Amini, A., Rus, D., &amp; Grosu, R. (2021).
Liquid time-constant networks. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 35(9), pp. 7657-7666.
<a class="reference external" href="https://doi.org/10.1609/aaai.v35i9.16936">doi: 10.1609/aaai.v35i9.16936</a>.</p>
</section>
</section>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(var(100vh)-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#model'" class="reference internal" href="#model">Model</a></li>
<li><a :data-current="activeSection === '#data'" class="reference internal" href="#data">Data</a><ul>
<li><a :data-current="activeSection === '#outputs'" class="reference internal" href="#outputs">Outputs</a></li>
<li><a :data-current="activeSection === '#inputs'" class="reference internal" href="#inputs">Inputs</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#code'" class="reference internal" href="#code">Code</a><ul>
<li><a :data-current="activeSection === '#environment-set-up'" class="reference internal" href="#environment-set-up">Environment Set-Up</a></li>
<li><a :data-current="activeSection === '#data-preparation'" class="reference internal" href="#data-preparation">Data Preparation</a></li>
<li><a :data-current="activeSection === '#training'" class="reference internal" href="#training">Training</a></li>
<li><a :data-current="activeSection === '#inference'" class="reference internal" href="#inference">Inference</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#references'" class="reference internal" href="#references">References</a></li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">Â© 
2023 fg-research. fg-research is an independent software vendor that provides machine learning solutions on the AWS Marketplace.
Amazon Web Services, AWS, Amazon SageMaker, AWS Marketplace and the AWS Marketplace logo are trademarks of Amazon.com, Inc. or its affiliates.
Â Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 7.2.6</a></p>
</div>
</div>
</footer>
</div>
<script src="../../../_static/documentation_options.js?v=953f42dc"></script>
<script src="../../../_static/doctools.js?v=888ff710"></script>
<script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../../../_static/theme.js?v=40b7bc71"></script>
<script src="../../../_static/design-tabs.js?v=36754332"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="../../../_static/custom.js?v=f9493bda"></script>
</body>
</html>